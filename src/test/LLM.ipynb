{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LLAMA3\n",
    "\n",
    "This notebook contains the implementation of the LLAMA3 large language model "
   ],
   "id": "3e537def6a073c19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>Importing Libraries</b>",
   "id": "3dbc9fbcad1aeb3c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd727a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "current_dir = %pwd\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '../..'))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a44988-38a7-48d1-a7da-43f39fb29398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch, gc\n",
    "import outlines\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from src.main.utilities.utils import get_dataset, split_train_val_test\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "access_token = \"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\"\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>Load the dataset</b>",
   "id": "a99d48e52f5a9b79"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c6c8e2-aa6f-4d94-a419-09744966179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = get_dataset(one_hot=False)\n",
    "inputs = inputs.reshape(-1)\n",
    "\n",
    "choices = [\"Entertainment\", \"Life\", \"Politics\", \"Sports\", \"Voices\"]\n",
    "\n",
    "_, _, x_test,_ ,_ , y_test = split_train_val_test(inputs, targets, test_size=0.1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b> Prepare prompt </b>",
   "id": "79e7d353a945aa21"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f6e3bad-8844-4a3e-a1b4-a9a899505598",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"News\": x_test}\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "\n",
    "def make_prompt(news, choices):\n",
    "    prompt = f\"\"\"\n",
    "    Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "    ### Instruction:\n",
    "    \n",
    "    The news items can be categories like below.\n",
    "    \n",
    "    Entertainment, Life, Politics, Sports, Voices\n",
    "    \n",
    "    Below is some example classifications. the format is the news item followed by classification tag.\n",
    "    \n",
    "    1. U.S. President Joe Biden, in London for the funeral of Queen Elizabeth II, says his heart went out to the royal family, adding the queen's death left a giant hole. <classification>Politics</classification>\n",
    "    \n",
    "    2. The Best Parts Of Fruits And Veggies You're Not Eating. Most adults would benefit from one and a half to two cups of fruit and two to three cups of vegetables each day. But it might. <classification>Life</classification>\n",
    "\n",
    "    3. This year marks the 60th Anniversary of On the Waterfront, the winner of the Best Picture Oscar for 1954. In honor of this weekend's Oscars, we're taking a look at what still makes this film such a timeless classic. <classification>Entertainment</classification>\n",
    "\n",
    "    4. The NBA may have proven itself to be unreliable on All-Star Saturday Night in New Orleans but NBA Twitter showed itself to. <classification>Sports</classification>\n",
    "\n",
    "    5. The talk show host sat down with Marlo Thomas and talked about how life has changed for lesbian, gay, bisexual and transgender. <classification>Voices</classification>\n",
    "    \n",
    "    Classify below news item.\n",
    "    \n",
    "    {news}\n",
    "    \n",
    "    ### Response:\n",
    "\n",
    "    <classification>\n",
    "    \n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459399c7-de99-4e80-90b9-b840e41b70e8",
   "metadata": {},
   "source": [
    "### Use  [Outlines](https://outlines-dev.github.io/outlines/) for forcing specific tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81c5922-2807-4fc7-a4b8-5d3f589397cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7e93c61f9b4184ba47943e9cbaaadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load the model with outlines\n",
    "model = outlines.models.transformers(model_id, model_kwargs={\"torch_dtype\": torch.float16}, device=\"cuda\")\n",
    "\n",
    "# load a generator with the model and possible choices\n",
    "generator = outlines.generate.choice(model, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496995c-23fd-4ef4-8208-f468a0c3b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlines_replies = []\n",
    "for news in x_test:\n",
    "    prompt = make_prompt(news, choices)\n",
    "    # generate reply with generator (will be one of choices)\n",
    "    reply = generator(prompt)\n",
    "    outlines_replies.append(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "346c06d0-7366-49fe-bb2a-1e13b6fee1b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Model response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer Recipes: Must-Have Dinner Party Menu Id...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joan Rivers Brands Jennifer Lawrence 'Arrogant...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don King On Mike Tyson: Boxing Promoter Respon...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hope That Helps If we can look deeply into wha...</td>\n",
       "      <td>Voices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 Days, 15 Ways to Feed Your Face in Tampa Bay...</td>\n",
       "      <td>Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10768</th>\n",
       "      <td>Trump Reportedly Considered 'Selling' Puerto R...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10769</th>\n",
       "      <td>Escape to Paradise In honor of Huffington Post...</td>\n",
       "      <td>Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10770</th>\n",
       "      <td>'Dump Trump' Takes A Political Movement And Fu...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10771</th>\n",
       "      <td>What's New On Netflix In March 2016? The retur...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10772</th>\n",
       "      <td>Rubio: Roe v. Wade Is 'Current Law, Not Settle...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10773 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    News Model response\n",
       "0      Summer Recipes: Must-Have Dinner Party Menu Id...  Entertainment\n",
       "1      Joan Rivers Brands Jennifer Lawrence 'Arrogant...  Entertainment\n",
       "2      Don King On Mike Tyson: Boxing Promoter Respon...         Sports\n",
       "3      Hope That Helps If we can look deeply into wha...         Voices\n",
       "4      5 Days, 15 Ways to Feed Your Face in Tampa Bay...           Life\n",
       "...                                                  ...            ...\n",
       "10768  Trump Reportedly Considered 'Selling' Puerto R...       Politics\n",
       "10769  Escape to Paradise In honor of Huffington Post...           Life\n",
       "10770  'Dump Trump' Takes A Political Movement And Fu...         Sports\n",
       "10771  What's New On Netflix In March 2016? The retur...  Entertainment\n",
       "10772  Rubio: Roe v. Wade Is 'Current Law, Not Settle...       Politics\n",
       "\n",
       "[10773 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Model response'] = outlines_replies\n",
    "df"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<b>Model evaluation</b>",
   "id": "47a55dc8d55903ba"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13e9364d-02d7-4640-83e0-850efc5fe3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Entertainment       0.42      0.71      0.52      1851\n",
      "         Life       0.95      0.23      0.37      4134\n",
      "     Politics       0.83      0.90      0.87      3208\n",
      "       Sports       0.27      0.93      0.42       470\n",
      "       Voices       0.36      0.50      0.42      1110\n",
      "\n",
      "     accuracy                           0.57     10773\n",
      "    macro avg       0.57      0.65      0.52     10773\n",
      " weighted avg       0.74      0.57      0.55     10773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, outlines_replies)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dfdbffc-daac-4936-864a-0f8791d99cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: {'Entertainment': 3127, 'Life': 994, 'Politics': 3476, 'Sports': 1643, 'Voices': 1533}\n",
      "Correct: {'Entertainment': 1305, 'Life': 949, 'Politics': 2896, 'Sports': 439, 'Voices': 556}\n",
      "Actual: {'Entertainment': 1851, 'Life': 4134, 'Politics': 3208, 'Sports': 470, 'Voices': 1110}\n",
      "Accuracy:  0.5704075002320617\n"
     ]
    }
   ],
   "source": [
    "correct = {\"Entertainment\":0, \"Life\":0, \"Politics\":0, \"Sports\":0, \"Voices\":0}\n",
    "output = {\"Entertainment\":0, \"Life\":0, \"Politics\":0, \"Sports\":0, \"Voices\":0}\n",
    "actual = {\"Entertainment\":0, \"Life\":0, \"Politics\":0, \"Sports\":0, \"Voices\":0}\n",
    "for i in df.index.values.tolist():\n",
    "    if df[\"Model response\"][i] == y_test[i]:\n",
    "        correct[y_test[i]] += 1\n",
    "    actual[y_test[i]] += 1\n",
    "    output[df[\"Model response\"][i]] += 1\n",
    "\n",
    "accuracy = sum(correct.values())/len(y_test)\n",
    "\n",
    "print(\"Output:\", output)\n",
    "print(\"Correct:\", correct)\n",
    "print(\"Actual:\", actual)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c082ca9-85b8-4f4e-af69-b41931433d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-24T08:37:56.875506Z",
     "start_time": "2024-05-24T08:37:56.872468Z"
    }
   },
   "source": [
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "current_dir = %pwd\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '../..'))\n",
    "sys.path.append(parent_dir)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7d730bf83640e57",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T09:10:35.004854Z",
     "start_time": "2024-05-24T09:10:24.158621Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.main.utilities.utils import get_dataset\n",
    "from src.main.pipeline.pipeline import Pipeline\n",
    "from src.main.pipeline.functions import stop_words_removal, clean_text, remove_contractions, unify_numbers, tfidf_vectorizer\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from yellowbrick.text import TSNEVisualizer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d620ffcdb22fe8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#create_report(dataset)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12a46edb",
   "metadata": {},
   "source": [
    "inputs, targets = get_dataset()\n",
    "targets_series = pd.Series(targets)\n",
    "class_counts = targets_series.value_counts()\n",
    "\n",
    "class_counts.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Number of Samples per Class')\n",
    "plt.xticks(rotation='horizontal') \n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a7b51c56",
   "metadata": {},
   "source": [
    "pipeline = Pipeline([remove_contractions, clean_text, stop_words_removal, unify_numbers])\n",
    "inputs, targets = get_dataset()\n",
    "results = pipeline.execute(inputs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fb5bfd1e",
   "metadata": {},
   "source": [
    "# Plot in mean how many caracter are removed after applying the pipeline for each class\n",
    "\n",
    "text_lengths = [len(text.split()) for text in results.reshape(-1).tolist()]\n",
    "clean_text_lengths = [len(text.split()) for text in results]\n",
    "print(np.mean(text_lengths) - np.mean(clean_text_lengths))\n",
    "\n",
    "dataframe = pd.DataFrame({'full_article': inputs.reshape(-1).tolist(), 'class': targets})\n",
    "\n",
    "dataframe['clean_text'] = results\n",
    "dataframe['text_length'] = dataframe['full_article'].apply(lambda x: len(x.split()))\n",
    "dataframe['clean_text_length'] = dataframe['clean_text'].apply(lambda x: len(x.split()))\n",
    "dataframe['text_length_diff'] = dataframe['text_length'] - dataframe['clean_text_length']\n",
    "dataframe['class'] = targets\n",
    "dataframe.groupby('class')['text_length_diff'].mean()\n",
    "\n",
    "dataframe.groupby('class')['text_length_diff'].mean().plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Mean difference in text length')\n",
    "plt.title('Mean difference in text length after cleaning')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d842d52c",
   "metadata": {},
   "source": [
    "# Plot the number of documents with each length without pipeline\n",
    "\n",
    "document_lengths = [len(text.split()) for text in inputs.reshape(-1).tolist()]\n",
    "\n",
    "document_lengths_count = {}\n",
    "for length in document_lengths:\n",
    "    if length in document_lengths_count:\n",
    "        document_lengths_count[length] += 1\n",
    "    else:\n",
    "        document_lengths_count[length] = 1\n",
    "\n",
    "plt.bar(document_lengths_count.keys(), document_lengths_count.values(), width=1)\n",
    "plt.xlabel('Document Length')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.title('Number of Documents with Each Length without Pipeline')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59cb8932",
   "metadata": {},
   "source": [
    "# Plot the number of documents with each length with pipeline\n",
    "\n",
    "document_lengths = [len(text.split()) for text in results.reshape(-1).tolist()]\n",
    "\n",
    "document_lengths_count = {}\n",
    "for length in document_lengths:\n",
    "    if length in document_lengths_count:\n",
    "        document_lengths_count[length] += 1\n",
    "    else:\n",
    "        document_lengths_count[length] = 1\n",
    "\n",
    "plt.bar(document_lengths_count.keys(), document_lengths_count.values(), width=1)\n",
    "plt.xlabel('Document Length')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.title('Number of Documents with Each Length with Pipeline')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "29ea7a31",
   "metadata": {},
   "source": [
    "# Variance of text length for every class\n",
    "dataframe['class'] = targets\n",
    "dataframe['text_length'] = dataframe['full_article'].apply(lambda x: len(x.split()))\n",
    "dataframe.groupby('class')['text_length'].var()\n",
    "\n",
    "# plot\n",
    "dataframe.groupby('class')['text_length'].var().plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Variance of text length')\n",
    "plt.title('Variance of text length for every class')\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b8e002e",
   "metadata": {},
   "source": [
    "# Word cloud of the most common words between the classes (with pipeline)\n",
    "\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = None, \n",
    "                min_font_size = 10).generate(' '.join(results.reshape(-1).tolist()))\n",
    "\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d551b73",
   "metadata": {},
   "source": [
    "# Average document length per class\n",
    "\n",
    "dict = {}\n",
    "for i in range(len(targets)):\n",
    "    if targets[i] in dict:\n",
    "        dict[targets[i]] += len(results[i].split())\n",
    "    else:\n",
    "        dict[targets[i]] = len(results[i].split())\n",
    "\n",
    "for key in dict:\n",
    "    dict[key] /= class_counts[key]\n",
    "\n",
    "\n",
    "plt.bar(dict.keys(), dict.values())\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Average Document Length')\n",
    "plt.title('Average Document Length per Class')\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58271ec4",
   "metadata": {},
   "source": [
    "pipeline = Pipeline([remove_contractions, clean_text, stop_words_removal]) # unify_numbers removed -> generate [NUM] tokens\n",
    "inputs, targets = get_dataset()\n",
    "results = pipeline.execute(inputs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85a8bb3d",
   "metadata": {},
   "source": [
    "# The three most common words fo each class\n",
    "\n",
    "dict = {}\n",
    "for i in range(len(targets)):\n",
    "    if targets[i] in dict:\n",
    "        dict[targets[i]] += results[i].split()\n",
    "    else:\n",
    "        dict[targets[i]] = results[i].split()\n",
    "\n",
    "for key in dict:\n",
    "    dict[key] = Counter(dict[key]).most_common(3)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(25, 5))\n",
    "fig.text(0.5, 0.0001, 'Word', ha='center')\n",
    "fig.text(0.09, 0.5, 'Count', va='center', rotation='vertical')\n",
    "for i, key in enumerate(dict):\n",
    "    words = [word[0] for word in dict[key]]\n",
    "    counts = [word[1] for word in dict[key]]\n",
    "    axs[i].bar(words, counts)\n",
    "    axs[i].set_title(key)\n",
    "    axs[i].set_xticklabels(words, rotation='horizontal')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69d6f228",
   "metadata": {},
   "source": [
    "# Plot a word cloud for each class\n",
    "\n",
    "dict = {}\n",
    "for i in range(len(targets)):\n",
    "    if targets[i] in dict:\n",
    "        dict[targets[i]] += results[i].split()\n",
    "    else:\n",
    "        dict[targets[i]] = results[i].split()\n",
    "\n",
    "for key in dict:\n",
    "    dict[key] = Counter(dict[key]).most_common(50)\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(25, 5))\n",
    "for i, key in enumerate(dict):\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                #stopwords = None, \n",
    "                min_font_size = 10).generate(' '.join([word[0] for word in dict[key]]))\n",
    "    axs[i].imshow(wordcloud)\n",
    "    axs[i].axis(\"off\")\n",
    "    axs[i].set_title(key)\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7c2929e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:39:00.758610Z",
     "start_time": "2024-05-24T09:38:59.080703Z"
    }
   },
   "source": [
    "pipeline = Pipeline([\n",
    "    remove_contractions,\n",
    "    clean_text,\n",
    "    stop_words_removal,\n",
    "    unify_numbers,\n",
    "    tfidf_vectorizer\n",
    "])\n",
    "\n",
    "inputs, targets = get_dataset()\n",
    "\n",
    "df = pd.DataFrame({'full_article': inputs.reshape(-1), 'label': targets})\n",
    "df = df.groupby(targets).head(2500)\n",
    "df = df[df['label'] != 'Voices']\n",
    "inputs = df['full_article'].values\n",
    "targets = df['label'].values\n",
    "results = pipeline.execute(inputs).reshape(-1)[0]  # [0] to get the sparse matrix\n"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "34adbf4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:39:31.152243Z",
     "start_time": "2024-05-24T09:39:00.759988Z"
    }
   },
   "source": [
    "tsne = TSNEVisualizer(colormap='viridis')\n",
    "tsne.fit(results, targets)\n",
    "tsne.show()"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "d708eb119f6d58ae",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
